{"projectId":"DOforDSX-UnitCommitment-example","modelId":"UCdeploy","decision":"UnitCommitment","scenario":"Scenario 1","name":"UCdeploy","description":"Scenario1 deployment","author":{"name":"admin"},"inputSchemas":[{"name":"periods","type":"struct","fields":[{"name":"id","type":"double","nullable":true},{"name":"day","type":"string","nullable":true},{"name":"time_of_day","type":"string","nullable":true}]},{"name":"units","type":"struct","fields":[{"name":"units","type":"string","nullable":true},{"name":"type","type":"string","nullable":true},{"name":"init_prod_level","type":"double","nullable":true},{"name":"min_generation","type":"double","nullable":true},{"name":"max_generation","type":"double","nullable":true},{"name":"operating_max_gen","type":"double","nullable":true},{"name":"min_up","type":"double","nullable":true},{"name":"min_down","type":"double","nullable":true},{"name":"ramp_up","type":"double","nullable":true},{"name":"ramp_down","type":"double","nullable":true},{"name":"start_up_cost","type":"double","nullable":true},{"name":"constant_cost","type":"double","nullable":true},{"name":"linear_cost","type":"double","nullable":true},{"name":"co2_cost","type":"double","nullable":true}]},{"name":"loads","type":"struct","fields":[{"name":"load","type":"double","nullable":true},{"name":"period","type":"double","nullable":true}]}],"outputSchemas":[{"name":"kpis","type":"struct","fields":[{"name":"kpi","type":"string","nullable":true},{"name":"value","type":"double","nullable":true}]},{"name":"used","type":"struct","fields":[{"name":"COAL_1","type":"double","nullable":true},{"name":"COAL_2","type":"double","nullable":true},{"name":"DIESEL_1","type":"double","nullable":true},{"name":"DIESEL_2","type":"double","nullable":true},{"name":"DIESEL_3","type":"double","nullable":true},{"name":"DIESEL_4","type":"double","nullable":true},{"name":"GAS_1","type":"double","nullable":true},{"name":"GAS_2","type":"double","nullable":true},{"name":"GAS_3","type":"double","nullable":true},{"name":"GAS_4","type":"double","nullable":true}]},{"name":"prods","type":"struct","fields":[{"name":"COAL_1","type":"double","nullable":true},{"name":"COAL_2","type":"double","nullable":true},{"name":"DIESEL_1","type":"double","nullable":true},{"name":"DIESEL_2","type":"double","nullable":true},{"name":"DIESEL_3","type":"double","nullable":true},{"name":"DIESEL_4","type":"string","nullable":true},{"name":"GAS_1","type":"double","nullable":true},{"name":"GAS_2","type":"double","nullable":true},{"name":"GAS_3","type":"double","nullable":true},{"name":"GAS_4","type":"double","nullable":true}]},{"name":"production","type":"struct","fields":[{"name":"value","type":"string","nullable":true},{"name":"units","type":"string","nullable":true},{"name":"periods","type":"double","nullable":true}]},{"name":"started","type":"struct","fields":[{"name":"COAL_1","type":"double","nullable":true},{"name":"COAL_2","type":"double","nullable":true},{"name":"DIESEL_1","type":"double","nullable":true},{"name":"DIESEL_2","type":"double","nullable":true},{"name":"DIESEL_3","type":"double","nullable":true},{"name":"DIESEL_4","type":"double","nullable":true},{"name":"GAS_1","type":"double","nullable":true},{"name":"GAS_2","type":"double","nullable":true},{"name":"GAS_3","type":"double","nullable":true},{"name":"GAS_4","type":"double","nullable":true}]}],"modelCode":[{"name":"model.py","code":"\r\nfrom docplex.mp.environment import Environment\r\nfrom docplex.mp.model import Model\r\nimport pandas as pd\r\n\r\nurl = None\r\nkey = None\r\n\r\ndf_units = inputs['units']\r\ndf_units.set_index(df_units[\"units\"], inplace=True)\r\ndf_periods = inputs['periods']\r\ndf_periods.set_index(df_periods[\"id\"], inplace=True)\r\ndf_loads = inputs['loads']\r\ndf_loads.set_index(df_loads[\"period\"], inplace=True)\r\n\r\nrobust = 0\r\n\r\nenv = Environment()\r\n#env.print_information()\r\n\r\nucpm = Model(\"ucp\")\r\nn_starts = None\r\n\r\nunits = df_units['units'].values.tolist()\r\n\r\nnb_periods = len(df_periods)\r\n\r\n# periods range from 1 to nb_periods included\r\nperiods = range(1, nb_periods+1)\r\n\r\n# in use[u,t] is true iff unit u is in production at period t\r\nin_use = ucpm.binary_var_matrix(keys1=units, keys2=periods, name=\"in_use\")\r\n\r\n# true if unit u is turned on at period t\r\nturn_on = ucpm.binary_var_matrix(keys1=units, keys2=periods, name=\"turn_on\")\r\n\r\n# true if unit u is switched off at period t\r\n# modeled as a continuous 0-1 variable, more on this later\r\nturn_off = ucpm.continuous_var_matrix(keys1=units, keys2=periods, lb=0, ub=1, name=\"turn_off\")\r\n\r\n# production of energy for unit u at period t\r\nproduction = ucpm.continuous_var_matrix(keys1=units, keys2=periods, name=\"production\")\r\n\r\n# Organize all decision variables in a DataFrame indexed by 'units' and 'periods'\r\ndf_decision_vars = pd.DataFrame({'in_use': in_use, 'turn_on': turn_on, 'turn_off': turn_off, 'production': production})\r\n\r\n# Set index names\r\ndf_decision_vars.index.names=['units', 'periods']\r\n\r\n# Create a join between 'df_decision_vars' and 'df_up' Data Frames based on common index id (ie: 'units')\r\n# In 'df_up', one keeps only relevant columns: 'min_gen' and 'max_gen'\r\ndf_join_decision_vars_up = df_decision_vars.join(df_units[['min_generation', 'max_generation']], how='inner')\r\n\r\n# When in use, the production level is constrained to be between min and max generation.\r\nfor item in df_join_decision_vars_up.itertuples(index=False):\r\n\tucpm += (item.production <= item.max_generation * item.in_use)\r\n\tucpm += (item.production >= item.min_generation * item.in_use)\r\n\t\r\n# Initial state\r\n# If initial production is nonzero, then period #1 is not a turn_on\r\n# else turn_on equals in_use\r\n# Dual logic is implemented for turn_off\r\nfor u in units:\r\n\tif df_units.init_prod_level[u] > 0:\r\n\t\t# if u is already running, not starting up\r\n\t\tucpm.add_constraint(turn_on[u, 1] == 0)\r\n\t\t# turnoff iff not in use\r\n\t\tucpm.add_constraint(turn_off[u, 1] + in_use[u, 1] == 1)\r\n\telse:\r\n\t\t# turn on at 1 iff in use at 1\r\n\t\tucpm.add_constraint(turn_on[u, 1] == in_use[u, 1])\r\n\t\t# already off, not switched off at t==1\r\n\t\tucpm.add_constraint(turn_off[u, 1] == 0)\r\n\t\t\r\n# Use groupby operation to process each unit\r\nfor unit, r in df_decision_vars.groupby(level='units'):\r\n\tu_ramp_up = df_units.ramp_up[unit]\r\n\tu_ramp_down = df_units.ramp_down[unit]\r\n\tu_initial = df_units.init_prod_level[unit]\r\n\t# Initial ramp up/down\r\n\t# Note that r.production is a Series that can be indexed as an array (ie: first item index = 0)\r\n\tucpm.add_constraint(r.production[0] - u_initial <= u_ramp_up)\r\n\tucpm.add_constraint(u_initial - r.production[0] <= u_ramp_down)\r\n\tfor (p_curr, p_next) in zip(r.production, r.production[1:]):\r\n\t\tucpm.add_constraint(p_next - p_curr <= u_ramp_up)\r\n\t\tucpm.add_constraint(p_curr - p_next <= u_ramp_down)         \r\n\t\t\r\n# Turn_on, turn_off\r\n# Use groupby operation to process each unit\r\nfor unit, r in df_decision_vars.groupby(level='units'):\r\n\tfor (in_use_curr, in_use_next, turn_on_next, turn_off_next) in zip(r.in_use, r.in_use[1:], r.turn_on[1:], r.turn_off[1:]):\r\n\t\t# if unit is off at time t and on at time t+1, then it was turned on at time t+1\r\n\t\tucpm.add_constraint(in_use_next - in_use_curr <= turn_on_next)\r\n\r\n\t\t# if unit is on at time t and time t+1, then it was not turned on at time t+1\r\n\t\t# mdl.add_constraint(in_use_next + in_use_curr + turn_on_next <= 2)\r\n\r\n\t\t# if unit is on at time t and off at time t+1, then it was turned off at time t+1\r\n\t\tucpm.add_constraint(in_use_curr - in_use_next + turn_on_next == turn_off_next)        \r\n\t\t\r\n# Minimum uptime, downtime\r\nfor unit, r in df_decision_vars.groupby(level='units'):\r\n\tmin_uptime   = df_units.min_up[unit]\r\n\tmin_downtime = df_units.min_down[unit]\r\n\t# Note that r.turn_on and r.in_use are Series that can be indexed as arrays (ie: first item index = 0)\r\n\tfor t in range(min_uptime, nb_periods):\r\n\t\tctname = \"min_up_{0!s}_{1}\".format(*r.index[t])\r\n\t\tucpm.add_constraint(ucpm.sum(r.turn_on[(t - min_uptime) + 1:t + 1]) <= r.in_use[t], ctname)\r\n\r\n\tfor t in range(min_downtime, nb_periods):\r\n\t\tctname = \"min_down_{0!s}_{1}\".format(*r.index[t])\r\n\t\tucpm.add_constraint(ucpm.sum(r.turn_off[(t - min_downtime) + 1:t + 1]) <= 1 - r.in_use[t], ctname)\r\n\t\t\r\n# Enforcing demand\r\n# we use a >= here to be more robust, \r\n# objective will ensure  we produce efficiently\r\nfor period, r in df_decision_vars.groupby(level='periods'):\r\n\ttotal_demand = df_loads.load[period]\r\n\tctname = \"ct_meet_demand_%d\" % period\r\n\tucpm.add_constraint(ucpm.sum(r.production) >= total_demand + robust, ctname) \r\n\t\r\n# Predefined usage\r\nif 'used' in inputs:\r\n\tdf_used = inputs['used']\r\n\tfor p in periods:\r\n\t\tfor u in units:\r\n\t\t\tucpm.add_constraint(in_use[u, p] == df_used[u][p])\r\n\t\t\t\r\n# Create a join between 'df_decision_vars' and 'df_up' Data Frames based on common index ids (ie: 'units')\r\n# In 'df_up', one keeps only relevant columns: 'fixed_cost', 'variable_cost', 'start_cost' and 'co2_cost'\r\ndf_join_obj = df_decision_vars.join(\r\n\tdf_units[['constant_cost', 'linear_cost', 'start_up_cost', 'co2_cost']], how='inner')        \r\n\t\t\r\n# objective\r\ntotal_fixed_cost = ucpm.sum(df_join_obj.in_use * df_join_obj.constant_cost)\r\ntotal_variable_cost = ucpm.sum(df_join_obj.production * df_join_obj.linear_cost)\r\ntotal_startup_cost = ucpm.sum(df_join_obj.turn_on * df_join_obj.start_up_cost)\r\ntotal_co2_cost = ucpm.sum(df_join_obj.production * df_join_obj.co2_cost)\r\ntotal_economic_cost = total_fixed_cost + total_variable_cost + total_startup_cost\r\ntotal_cost = total_economic_cost + total_co2_cost\r\n\r\ntotal_nb_used = ucpm.sum(df_decision_vars.in_use)\r\ntotal_nb_starts = ucpm.sum(df_decision_vars.turn_on)\r\n\r\nif (n_starts is not None):\r\n\tucpm.add_constraint(total_nb_starts == n_starts)\r\n\r\n# store expression kpis to retrieve them later.\r\nucpm.add_kpi(total_fixed_cost   , \"Total Fixed Cost\")\r\nucpm.add_kpi(total_variable_cost, \"Total Variable Cost\")\r\nucpm.add_kpi(total_startup_cost , \"Total Startup Cost\")\r\nucpm.add_kpi(total_economic_cost, \"Total Economic Cost\")\r\nucpm.add_kpi(total_co2_cost     , \"Total CO2 Cost\")\r\nucpm.add_kpi(total_cost         , \"Total Cost\")\r\nucpm.add_kpi(total_nb_used, \"Total #used\")\r\nucpm.add_kpi(total_nb_starts, \"Total #starts\")\r\n\r\n# minimize sum of all costs\r\nucpm.minimize(total_fixed_cost + total_variable_cost + total_startup_cost + total_co2_cost)\r\n\r\nif ucpm.solve(url=url, key=key):\r\n\tprint \"  Feasible \" + str(ucpm.objective_value)\r\n\r\n\tdf_prods = df_decision_vars.production.apply(lambda v: v.solution_value).unstack(level='units')\r\n\tdf_used = df_decision_vars.in_use.apply(lambda v: v.solution_value).unstack(level='units')\r\n\tdf_started = df_decision_vars.turn_on.apply(lambda v: v.solution_value).unstack(level='units')\r\n\r\n\tall_kpis = [(kp.name, kp.compute()) for kp in ucpm.iter_kpis()]\r\n\tall_kpis.append((\"Feasibility\", 1))\r\n\tkpis_bd = pd.DataFrame(all_kpis, columns=['kpi', 'value'])\r\n\r\n\tdf_production = df_prods.copy()\r\n\tdf_production = df_production.stack(level='units').to_frame()\r\n\tdf_production['units'] = df_production.index.get_level_values('units') \r\n\tdf_production['periods'] = df_production.index.get_level_values('periods') \r\n\tdf_production.columns = ['value', 'units', 'periods'] \r\n\tdf_production = df_production.reset_index(drop=True)\r\n\toutputs = {}\r\n\toutputs['production'] = df_production\r\n\toutputs['prods'] = df_prods\r\n\toutputs['used'] = df_used\r\n\toutputs['started'] = df_started\r\n\toutputs['kpis'] = kpis_bd\r\nelse:\r\n\tprint \"  Infeasible\"\r\n\tall_kpis= [(\"Feasibility\", 0)]\r\n\tkpis_bd = pd.DataFrame(all_kpis, columns=['kpi', 'value'])\r\n\toutputs = {}\r\n\toutputs['kpis'] = kpis_bd\r\n"},{"name":"main.py","code":"from functools import partial, wraps\r\nimport os\r\nfrom os.path import splitext\r\nimport time\r\nimport threading\r\nimport traceback\r\nimport sys\r\n\r\nimport pandas\r\nfrom six import iteritems\r\n\r\nfrom docplex.util.environment import get_environment\r\n\r\noutput_lock = threading.Lock()\r\n\r\n\r\ndef set_stop_callback(cb):\r\n    env = get_environment()\r\n    env.abort_callbacks += [cb]\r\n\r\n\r\ndef get_all_inputs():\r\n    '''Utility method to read a list of files and return a tuple with all\r\n    read data frames.\r\n    Returns:\r\n        a map { datasetname: data frame }\r\n    '''\r\n    result = {}\r\n    env = get_environment()\r\n    for iname in [f for f in os.listdir('.') if splitext(f)[1] == '.csv']:\r\n        with env.get_input_stream(iname) as in_stream:\r\n            df = pandas.read_csv(in_stream)\r\n            datasetname, _ = splitext(iname)\r\n            result[datasetname] = df\r\n    return result\r\n\r\n\r\ndef callonce(f):\r\n    @wraps(f)\r\n    def wrapper(*args, **kwargs):\r\n        if not wrapper.called:\r\n            wrapper.called = True\r\n            return f(*args, **kwargs)\r\n    wrapper.called = False\r\n    return wrapper\r\n\r\n\r\n@callonce\r\ndef write_all_outputs(outputs):\r\n    '''Write all dataframes in ``outputs`` as .csv.\r\n\r\n    Args:\r\n        outputs: The map of outputs 'outputname' -> 'output df'\r\n    '''\r\n    global output_lock\r\n    with output_lock:\r\n        for (name, df) in iteritems(outputs):\r\n            csv_file = '%s.csv' % name\r\n            with get_environment().get_output_stream(csv_file) as fp:\r\n                if sys.version_info[0] < 3:\r\n                    fp.write(df.to_csv(index=False, encoding='utf8'))\r\n                else:\r\n                    fp.write(df.to_csv(index=False).encode(encoding='utf8'))\r\n    if len(outputs) == 0:\r\n        print(\"Warning: no outputs written\")\r\n\r\n\r\ndef wait_and_save_all_cb(outputs):\r\n    global output_lock\r\n    # just wait for the output_lock to be available\r\n    t = time.time()\r\n    with output_lock:\r\n        pass\r\n    elapsed = time.time() - t\r\n    # write outputs\r\n    write_all_outputs(outputs)\r\n\r\n\r\ndef get_line_of_model(n):\r\n    env = get_environment()\r\n    with env.get_input_stream('model.py') as m:\r\n        lines = m.readlines()\r\n        return lines[n - 1]\r\n\r\n\r\nclass InterpreterError(Exception):\r\n    pass\r\n\r\nif __name__ == '__main__':\r\n    inputs = get_all_inputs()\r\n    outputs = {}\r\n    set_stop_callback(partial(wait_and_save_all_cb, outputs))\r\n\r\n    env = get_environment()\r\n    # The IS_DODS env must be True for model.py if running in DODS\r\n    os.environ['IS_DODS'] = 'True'\r\n    # This allows docplex.mp to behave the same (publish kpis.csv and solution.json\r\n    # if this script is run locally\r\n    os.environ['DOCPLEX_CONTEXT'] = 'solver.auto_publish=True'\r\n    with env.get_input_stream('model.py') as m:\r\n        try:\r\n            exec(m.read().decode('utf-8'), globals())\r\n        except SyntaxError as err:\r\n            error_class = err.__class__.__name__\r\n            detail = err.args[0]\r\n            line_number = err.lineno\r\n            imsg = 'File \"model.py\", line %s\\n' % line_number\r\n            imsg += err.text.rstrip() + '\\n'\r\n            spaces = ' ' * (err.offset - 1) if err.offset > 1 else ''\r\n            imsg += spaces + \"^\\n\"\r\n            imsg += '%s: %s\\n' % (error_class, detail)\r\n            raise InterpreterError(imsg)\r\n        except Exception as err:\r\n            error_class = err.__class__.__name__\r\n            detail = err.args[0]\r\n            cl, exc, tb = sys.exc_info()\r\n            ttb = traceback.extract_tb(tb)\r\n            ttb[1] = ('model.py', ttb[1][1], ttb[1][2],\r\n                      get_line_of_model(ttb[1][1]))\r\n            line_number = ttb[1][1]\r\n            ttb = ttb[1:]\r\n            s = traceback.format_list(ttb)\r\n            imsg = (''.join(s))\r\n            imsg += '%s: %s\\n' % (error_class, detail)\r\n            raise InterpreterError(imsg)\r\n        else:\r\n            write_all_outputs(outputs)\r\n\r\n"}],"solveParameters":{"oaas.logAttachmentName":"log.txt","oaas.logTailEnabled":"true"},"dateCreated":1556048157591}